{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5007e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare\n",
    "import project_acquire\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea0a868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a4043c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=prepare.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2fdd69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rdpeng/ExData_Plotting1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nThis assignment uses data f...</td>\n",
       "      <td>introductionthi assign use data fromth uc irvi...</td>\n",
       "      <td>introductionthis assignment us data fromthe uc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdpeng/RepData_PeerAssessment1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nIt is now possible to colle...</td>\n",
       "      <td>introductionit possibl collect larg amount dat...</td>\n",
       "      <td>introductionit possible collect large amount d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataScienceSpecialization/courses</td>\n",
       "      <td>HTML</td>\n",
       "      <td>\\n### Data Science Specialization\\n\\nThese are...</td>\n",
       "      <td>data scienc specializationthes cours materi jo...</td>\n",
       "      <td>data science specializationthese course materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fighting41love/funNLP</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;center&gt;\\n    &lt;img style=\"border-radius: 0.312...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>magento/magento2</td>\n",
       "      <td>PHP</td>\n",
       "      <td>\\n&lt;p align=\"center\"&gt;\\n&lt;a href=\"https://www.cod...</td>\n",
       "      <td>magento open sourcewelcom magento open sourc p...</td>\n",
       "      <td>magento open sourcewelcome magento open source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rprokap/pset-9</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># pset-9\\n      CREDITS SEQUENCE              ...</td>\n",
       "      <td>pset9credit sequencenewspap headlin montagehea...</td>\n",
       "      <td>pset9credits sequencenewspaper headline montag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>konzy/mass_clone</td>\n",
       "      <td>Shell</td>\n",
       "      <td># mass_clone\\nThis is a shell script that will...</td>\n",
       "      <td>massclonethi shell script clone multipl reposi...</td>\n",
       "      <td>massclonethis shell script clone multiple repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>biter777/countries</td>\n",
       "      <td>Go</td>\n",
       "      <td># countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...</td>\n",
       "      <td>countriescountri iso 3166 iso31661 iso3166 dig...</td>\n",
       "      <td>countriescountries iso 3166 iso31661 iso3166 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>sayantann11/all-classification-templetes-for-ML</td>\n",
       "      <td>Python</td>\n",
       "      <td># all-classification-templetes-for-ML\\nClassif...</td>\n",
       "      <td>allclassificationtempletesformlclassif machin ...</td>\n",
       "      <td>allclassificationtempletesformlclassification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>denman2328/Help</td>\n",
       "      <td>None</td>\n",
       "      <td>------------------\\nSystem Information\\n------...</td>\n",
       "      <td>system informationtim report 8102013 083620 ma...</td>\n",
       "      <td>system informationtime report 8102013 083620 m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo    language  \\\n",
       "0                            rdpeng/ExData_Plotting1        None   \n",
       "1                     rdpeng/RepData_PeerAssessment1        None   \n",
       "2                  DataScienceSpecialization/courses        HTML   \n",
       "3                              fighting41love/funNLP      Python   \n",
       "4                                   magento/magento2         PHP   \n",
       "..                                               ...         ...   \n",
       "485                                   rprokap/pset-9  JavaScript   \n",
       "486                                 konzy/mass_clone       Shell   \n",
       "487                               biter777/countries          Go   \n",
       "488  sayantann11/all-classification-templetes-for-ML      Python   \n",
       "489                                  denman2328/Help        None   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "0    ## Introduction\\n\\nThis assignment uses data f...   \n",
       "1    ## Introduction\\n\\nIt is now possible to colle...   \n",
       "2    \\n### Data Science Specialization\\n\\nThese are...   \n",
       "3    <center>\\n    <img style=\"border-radius: 0.312...   \n",
       "4    \\n<p align=\"center\">\\n<a href=\"https://www.cod...   \n",
       "..                                                 ...   \n",
       "485  # pset-9\\n      CREDITS SEQUENCE              ...   \n",
       "486  # mass_clone\\nThis is a shell script that will...   \n",
       "487  # countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...   \n",
       "488  # all-classification-templetes-for-ML\\nClassif...   \n",
       "489  ------------------\\nSystem Information\\n------...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "0    introductionthi assign use data fromth uc irvi...   \n",
       "1    introductionit possibl collect larg amount dat...   \n",
       "2    data scienc specializationthes cours materi jo...   \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...   \n",
       "4    magento open sourcewelcom magento open sourc p...   \n",
       "..                                                 ...   \n",
       "485  pset9credit sequencenewspap headlin montagehea...   \n",
       "486  massclonethi shell script clone multipl reposi...   \n",
       "487  countriescountri iso 3166 iso31661 iso3166 dig...   \n",
       "488  allclassificationtempletesformlclassif machin ...   \n",
       "489  system informationtim report 8102013 083620 ma...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    introductionthis assignment us data fromthe uc...  \n",
       "1    introductionit possible collect large amount d...  \n",
       "2    data science specializationthese course materi...  \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...  \n",
       "4    magento open sourcewelcome magento open source...  \n",
       "..                                                 ...  \n",
       "485  pset9credits sequencenewspaper headline montag...  \n",
       "486  massclonethis shell script clone multiple repo...  \n",
       "487  countriescountries iso 3166 iso31661 iso3166 d...  \n",
       "488  allclassificationtempletesformlclassification ...  \n",
       "489  system informationtime report 8102013 083620 m...  \n",
       "\n",
       "[490 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0922896",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['r', 'u', '2', 'ltgt']\n",
    "\n",
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce42c2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>71</td>\n",
       "      <td>0.194521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>66</td>\n",
       "      <td>0.180822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>55</td>\n",
       "      <td>0.150685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assembly</th>\n",
       "      <td>39</td>\n",
       "      <td>0.106849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>22</td>\n",
       "      <td>0.060274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>21</td>\n",
       "      <td>0.057534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHP</th>\n",
       "      <td>16</td>\n",
       "      <td>0.043836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C#</th>\n",
       "      <td>14</td>\n",
       "      <td>0.038356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>12</td>\n",
       "      <td>0.032877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell</th>\n",
       "      <td>9</td>\n",
       "      <td>0.024658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter Notebook</th>\n",
       "      <td>6</td>\n",
       "      <td>0.016438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerShell</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Go</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSQL</th>\n",
       "      <td>3</td>\n",
       "      <td>0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dockerfile</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swift</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vue</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruby</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Objective-C++</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julia</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emacs Lisp</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Objective-C</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kotlin</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jinja</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCSS</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brainfuck</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rich Text Format</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VHDL</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n   percent\n",
       "Python            71  0.194521\n",
       "Java              66  0.180822\n",
       "JavaScript        55  0.150685\n",
       "Assembly          39  0.106849\n",
       "HTML              22  0.060274\n",
       "C++               21  0.057534\n",
       "PHP               16  0.043836\n",
       "C#                14  0.038356\n",
       "C                 12  0.032877\n",
       "Shell              9  0.024658\n",
       "Jupyter Notebook   6  0.016438\n",
       "CSS                4  0.010959\n",
       "PowerShell         4  0.010959\n",
       "Go                 4  0.010959\n",
       "TSQL               3  0.008219\n",
       "Dockerfile         2  0.005479\n",
       "R                  2  0.005479\n",
       "Swift              2  0.005479\n",
       "Vue                2  0.005479\n",
       "Ruby               1  0.002740\n",
       "Objective-C++      1  0.002740\n",
       "Julia              1  0.002740\n",
       "Emacs Lisp         1  0.002740\n",
       "Objective-C        1  0.002740\n",
       "Kotlin             1  0.002740\n",
       "Jinja              1  0.002740\n",
       "SCSS               1  0.002740\n",
       "Brainfuck          1  0.002740\n",
       "Rich Text Format   1  0.002740\n",
       "VHDL               1  0.002740"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['n', 'percent']\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99c26434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<490x53151 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 982263 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8543b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa4b8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2867646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introductionthis': 26535,\n",
       " 'assignment': 8901,\n",
       " 'us': 49395,\n",
       " 'data': 15978,\n",
       " 'fromthe': 21947,\n",
       " 'uc': 48751,\n",
       " 'irvine': 26763,\n",
       " 'machinelearning': 30843,\n",
       " 'repository': 40442,\n",
       " 'popular': 37360,\n",
       " 'machine': 30838,\n",
       " 'learningdatasets': 28722,\n",
       " 'particular': 36168,\n",
       " 'using': 49683,\n",
       " 'individual': 25728,\n",
       " 'householdelectric': 24756,\n",
       " 'power': 37527,\n",
       " 'consumption': 14293,\n",
       " 'set': 42689,\n",
       " 'made': 30880,\n",
       " 'available': 9317,\n",
       " 'onthe': 35036,\n",
       " 'course': 14865,\n",
       " 'web': 50961,\n",
       " 'site': 43436,\n",
       " 'dataset': 16025,\n",
       " 'electric': 18867,\n",
       " '20mb': 3893,\n",
       " 'description': 16738,\n",
       " 'measurement': 31528,\n",
       " 'inone': 26005,\n",
       " 'household': 24755,\n",
       " 'oneminute': 34941,\n",
       " 'sampling': 41768,\n",
       " 'rate': 39323,\n",
       " 'period': 36593,\n",
       " 'almost4': 7670,\n",
       " 'year': 52765,\n",
       " 'different': 17116,\n",
       " 'electrical': 18868,\n",
       " 'quantity': 39039,\n",
       " 'submetering': 45547,\n",
       " 'valuesare': 50010,\n",
       " 'availablethe': 9324,\n",
       " 'following': 21447,\n",
       " 'variable': 50050,\n",
       " 'takenfromthe': 46342,\n",
       " 'uciweb': 48753,\n",
       " 'sitedate': 43441,\n",
       " 'date': 16055,\n",
       " 'format': 21612,\n",
       " 'ddmmyyyy': 16174,\n",
       " 'time': 47503,\n",
       " 'hhmmss': 24350,\n",
       " 'globalactivepower': 22974,\n",
       " 'global': 22973,\n",
       " 'minuteaveraged': 32199,\n",
       " 'active': 7021,\n",
       " 'kilowatt': 27948,\n",
       " 'globalreactivepower': 22984,\n",
       " 'reactive': 39572,\n",
       " 'voltage': 50639,\n",
       " 'volt': 50637,\n",
       " 'globalintensity': 22979,\n",
       " 'current': 15374,\n",
       " 'intensity': 26326,\n",
       " 'ampere': 7802,\n",
       " 'submetering1': 45548,\n",
       " 'energy': 19207,\n",
       " 'watthour': 50893,\n",
       " 'corresponds': 14724,\n",
       " 'kitchen': 27981,\n",
       " 'containing': 14321,\n",
       " 'mainly': 30951,\n",
       " 'dishwasher': 17375,\n",
       " 'oven': 35660,\n",
       " 'microwave': 31965,\n",
       " 'hot': 24735,\n",
       " 'plate': 37014,\n",
       " 'gas': 22296,\n",
       " 'powered': 37536,\n",
       " 'submetering2': 45549,\n",
       " 'laundry': 28399,\n",
       " 'room': 41234,\n",
       " 'washingmachine': 50852,\n",
       " 'tumbledrier': 48546,\n",
       " 'refrigerator': 39974,\n",
       " 'light': 29073,\n",
       " 'submetering3': 45550,\n",
       " 'waterheater': 50878,\n",
       " 'airconditioner': 7454,\n",
       " 'loading': 30242,\n",
       " 'datawhen': 16051,\n",
       " 'please': 37052,\n",
       " 'consider': 14172,\n",
       " '2075259': 3869,\n",
       " 'row': 41337,\n",
       " 'column': 13543,\n",
       " 'firstcalculate': 21162,\n",
       " 'rough': 41313,\n",
       " 'estimate': 19573,\n",
       " 'much': 32962,\n",
       " 'memory': 31675,\n",
       " 'requirein': 40579,\n",
       " 'reading': 39609,\n",
       " 'make': 30986,\n",
       " 'sure': 45831,\n",
       " 'computer': 13866,\n",
       " 'enoughmemory': 19291,\n",
       " 'modern': 32457,\n",
       " 'fine': 21099,\n",
       " '20070201': 2935,\n",
       " 'and20070202': 7869,\n",
       " 'one': 34916,\n",
       " 'alternative': 7718,\n",
       " 'read': 39584,\n",
       " 'datesrather': 16065,\n",
       " 'entire': 19330,\n",
       " 'subsetting': 45589,\n",
       " 'thosedates': 47265,\n",
       " 'may': 31390,\n",
       " 'find': 21072,\n",
       " 'useful': 49482,\n",
       " 'convert': 14526,\n",
       " 'todatetime': 47777,\n",
       " 'class': 12995,\n",
       " 'strptime': 45421,\n",
       " 'asdatefunctions': 8751,\n",
       " 'note': 34118,\n",
       " 'missing': 32258,\n",
       " 'value': 49990,\n",
       " 'coded': 13381,\n",
       " 'making': 31002,\n",
       " 'plotsour': 37081,\n",
       " 'overall': 35661,\n",
       " 'goal': 23016,\n",
       " 'simply': 43346,\n",
       " 'examine': 19831,\n",
       " 'usagevaries': 49422,\n",
       " '2day': 4412,\n",
       " 'february': 20739,\n",
       " '2007': 2933,\n",
       " 'task': 46427,\n",
       " 'toreconstruct': 47949,\n",
       " 'plot': 37067,\n",
       " 'constructedusing': 14255,\n",
       " 'base': 9751,\n",
       " 'plotting': 37085,\n",
       " 'systemfirst': 46156,\n",
       " 'need': 33482,\n",
       " 'fork': 21589,\n",
       " 'clone': 13131,\n",
       " 'github': 22787,\n",
       " 'repositoryfor': 40453,\n",
       " 'construct': 14253,\n",
       " 'save': 41858,\n",
       " 'png': 37121,\n",
       " 'file': 20902,\n",
       " 'width': 51308,\n",
       " '480pixels': 5195,\n",
       " 'height': 24166,\n",
       " '480': 5192,\n",
       " 'pixel': 36942,\n",
       " 'name': 33271,\n",
       " 'plot1png': 37068,\n",
       " 'plot2png': 37070,\n",
       " 'etc': 19587,\n",
       " 'create': 15079,\n",
       " 'separate': 42544,\n",
       " 'code': 13357,\n",
       " 'plot1r': 37069,\n",
       " 'plot2r': 37071,\n",
       " 'thatconstructs': 46891,\n",
       " 'corresponding': 14723,\n",
       " 'ie': 25230,\n",
       " 'constructsthe': 14270,\n",
       " 'include': 25613,\n",
       " 'readingthe': 39614,\n",
       " 'fully': 22076,\n",
       " 'reproduced': 40504,\n",
       " 'alsoinclude': 7702,\n",
       " 'creates': 15092,\n",
       " 'add': 7068,\n",
       " 'git': 22769,\n",
       " 'repositorywhen': 40469,\n",
       " 'finished': 21116,\n",
       " 'push': 38649,\n",
       " 'togithub': 47811,\n",
       " 'version': 50215,\n",
       " 'todate': 47776,\n",
       " 'four': 21751,\n",
       " 'filesthe': 20979,\n",
       " 'shown': 43093,\n",
       " '1plot': 2833,\n",
       " 'chunk': 12833,\n",
       " 'unnamedchunk2figureunnamedchunk2png': 49140,\n",
       " '2plot': 4460,\n",
       " 'unnamedchunk3figureunnamedchunk3png': 49141,\n",
       " '3plot': 4894,\n",
       " 'unnamedchunk4figureunnamedchunk4png': 49142,\n",
       " '4plot': 5295,\n",
       " 'unnamedchunk5figureunnamedchunk5png': 49143,\n",
       " 'introductionit': 26531,\n",
       " 'possible': 37457,\n",
       " 'collect': 13480,\n",
       " 'large': 28318,\n",
       " 'amount': 7800,\n",
       " 'personalmovement': 36651,\n",
       " 'activity': 7031,\n",
       " 'monitoring': 32627,\n",
       " 'device': 16933,\n",
       " 'afitbit': 7325,\n",
       " 'nikefuelband': 33753,\n",
       " 'orjawbone': 35387,\n",
       " 'type': 48653,\n",
       " 'part': 36152,\n",
       " 'ofthe': 34623,\n",
       " 'quantified': 39037,\n",
       " 'self': 42423,\n",
       " 'movement': 32816,\n",
       " 'group': 23449,\n",
       " 'enthusiast': 19328,\n",
       " 'takemeasurements': 46339,\n",
       " 'regularly': 40099,\n",
       " 'improve': 25553,\n",
       " 'health': 24109,\n",
       " 'tofind': 47800,\n",
       " 'pattern': 36295,\n",
       " 'behavior': 9973,\n",
       " 'tech': 46514,\n",
       " 'geek': 22424,\n",
       " 'butthese': 11423,\n",
       " 'remain': 40241,\n",
       " 'underutilized': 48957,\n",
       " 'raw': 39351,\n",
       " 'hard': 23888,\n",
       " 'toobtain': 47883,\n",
       " 'lack': 28237,\n",
       " 'statistical': 44998,\n",
       " 'method': 31850,\n",
       " 'software': 43895,\n",
       " 'forprocessing': 21675,\n",
       " 'interpreting': 26444,\n",
       " 'datathis': 16043,\n",
       " 'use': 49453,\n",
       " 'personal': 36647,\n",
       " 'monitoringdevice': 32628,\n",
       " 'minute': 32197,\n",
       " 'interval': 26470,\n",
       " 'theday': 46941,\n",
       " 'consists': 14188,\n",
       " 'two': 48639,\n",
       " 'month': 32658,\n",
       " 'anonymousindividual': 8004,\n",
       " 'collected': 13482,\n",
       " 'october': 34532,\n",
       " 'november': 34200,\n",
       " '2012and': 2973,\n",
       " 'number': 34319,\n",
       " 'step': 45125,\n",
       " 'taken': 46340,\n",
       " 'day': 16105,\n",
       " 'datathe': 16042,\n",
       " 'downloaded': 18095,\n",
       " 'website': 51007,\n",
       " '52kthe': 5427,\n",
       " 'included': 25615,\n",
       " 'taking': 46350,\n",
       " '5minute': 5599,\n",
       " 'missingvalues': 32263,\n",
       " 'na': 33241,\n",
       " 'yyyymmddformat': 52971,\n",
       " 'identifier': 25180,\n",
       " 'whichmeasurement': 51233,\n",
       " 'takenthe': 46346,\n",
       " 'stored': 45236,\n",
       " 'commaseparatedvalue': 13607,\n",
       " 'csv': 15267,\n",
       " 'thereare': 47068,\n",
       " 'total': 47981,\n",
       " '17568': 2336,\n",
       " 'observation': 34471,\n",
       " 'thisdataset': 47179,\n",
       " 'assignmentthis': 8910,\n",
       " 'described': 16735,\n",
       " 'multiple': 33013,\n",
       " 'towrite': 48035,\n",
       " 'report': 40416,\n",
       " 'answer': 8018,\n",
       " 'question': 39076,\n",
       " 'detailed': 16835,\n",
       " 'ultimatelyyou': 48830,\n",
       " 'complete': 13780,\n",
       " 'single': 43401,\n",
       " 'rmarkdown': 41111,\n",
       " 'document': 17838,\n",
       " 'processed': 38081,\n",
       " 'knitr': 28046,\n",
       " 'betransformed': 10153,\n",
       " 'html': 24811,\n",
       " 'filethroughout': 21004,\n",
       " 'always': 7738,\n",
       " 'youused': 52938,\n",
       " 'generate': 22523,\n",
       " 'output': 35566,\n",
       " 'present': 37836,\n",
       " 'writing': 52047,\n",
       " 'inthe': 26481,\n",
       " 'markdown': 31190,\n",
       " 'echo': 18619,\n",
       " 'true': 48391,\n",
       " 'someone': 43974,\n",
       " 'elsewill': 18929,\n",
       " 'able': 6772,\n",
       " 'evaluated': 19682,\n",
       " 'viapeer': 50299,\n",
       " 'assessment': 8889,\n",
       " 'essential': 19556,\n",
       " 'peer': 36487,\n",
       " 'evaluator': 19686,\n",
       " 'ableto': 6773,\n",
       " 'review': 40898,\n",
       " 'analysisfor': 7841,\n",
       " 'aspect': 8838,\n",
       " 'feel': 20763,\n",
       " 'free': 21834,\n",
       " 'anyplotting': 8118,\n",
       " 'system': 46104,\n",
       " 'lattice': 28379,\n",
       " 'ggplot2forkclone': 22692,\n",
       " 'created': 15083,\n",
       " 'thisassignment': 47174,\n",
       " 'youwill': 52939,\n",
       " 'submit': 45552,\n",
       " 'pushing': 38658,\n",
       " 'completed': 13789,\n",
       " 'yourforked': 52900,\n",
       " 'submission': 45551,\n",
       " 'consist': 14182,\n",
       " 'url': 49365,\n",
       " 'sha1': 42810,\n",
       " 'commit': 13637,\n",
       " 'id': 25151,\n",
       " 'yourrepository': 52910,\n",
       " 'statenote': 44962,\n",
       " 'also': 7697,\n",
       " 'contains': 14323,\n",
       " 'theassignment': 46924,\n",
       " 'download': 18091,\n",
       " 'separately': 42547,\n",
       " 'preprocessing': 37824,\n",
       " 'datashow': 16037,\n",
       " 'needed': 33486,\n",
       " 'to1': 47748,\n",
       " 'load': 30228,\n",
       " 'readcsv2': 39593,\n",
       " 'processtransform': 38116,\n",
       " 'necessary': 33471,\n",
       " 'suitable': 45680,\n",
       " 'analysis': 7837,\n",
       " 'mean': 31493,\n",
       " 'per': 36545,\n",
       " 'dayfor': 16113,\n",
       " 'ignore': 25285,\n",
       " 'dataset1': 16026,\n",
       " 'histogram': 24485,\n",
       " 'day2': 16107,\n",
       " 'calculate': 11650,\n",
       " 'median': 31560,\n",
       " 'average': 9339,\n",
       " 'daily': 15898,\n",
       " 'pattern1': 36296,\n",
       " 'series': 42616,\n",
       " 'xaxis': 52320,\n",
       " 'averaged': 9341,\n",
       " 'across': 6992,\n",
       " 'yaxis2': 52756,\n",
       " 'maximum': 31377,\n",
       " 'imputing': 25562,\n",
       " 'valuesnote': 50022,\n",
       " 'daysintervals': 16130,\n",
       " 'presence': 37834,\n",
       " 'introducebias': 26520,\n",
       " 'calculation': 11655,\n",
       " 'summary': 45709,\n",
       " 'data1': 15980,\n",
       " 'nas2': 33337,\n",
       " 'devise': 16983,\n",
       " 'strategy': 45285,\n",
       " 'filling': 21018,\n",
       " 'sophisticated': 44020,\n",
       " 'example': 19834,\n",
       " 'could': 14771,\n",
       " 'meanmedian': 31506,\n",
       " 'etc3': 19589,\n",
       " 'new': 33627,\n",
       " 'equal': 19422,\n",
       " 'original': 35372,\n",
       " 'filled': 21013,\n",
       " 'in4': 25570,\n",
       " 'differ': 17110,\n",
       " 'first': 21158,\n",
       " 'impact': 25465,\n",
       " 'difference': 17111,\n",
       " 'weekday': 51054,\n",
       " 'weekendsfor': 51056,\n",
       " 'function': 22088,\n",
       " 'help': 24213,\n",
       " 'usethe': 49673,\n",
       " 'filledin': 21014,\n",
       " 'part1': 36153,\n",
       " 'factor': 20417,\n",
       " 'level': 28849,\n",
       " 'weekend': 51055,\n",
       " 'indicating': 25714,\n",
       " 'whether': 51229,\n",
       " 'given': 22931,\n",
       " 'day1': 16106,\n",
       " 'panel': 35968,\n",
       " 'yaxis': 52755,\n",
       " 'look': 30465,\n",
       " 'something': 43980,\n",
       " 'like': 29089,\n",
       " 'simulated': 43357,\n",
       " 'datasample': 16023,\n",
       " 'plotinstructionsfigsamplepanelplotpng': 37073,\n",
       " 'willbe': 51348,\n",
       " 'monitor': 32626,\n",
       " 'madeusing': 30884,\n",
       " 'plotusing': 37086,\n",
       " 'choose': 12789,\n",
       " 'submitting': 45555,\n",
       " 'assignmentto': 8911,\n",
       " 'assignment1': 8902,\n",
       " 'pa1templatermd': 35787,\n",
       " 'master': 31282,\n",
       " 'branch': 10884,\n",
       " 'already': 7689,\n",
       " 'unless': 49115,\n",
       " 'ones2': 34952,\n",
       " 'pa1templatemd': 35786,\n",
       " 'pa1templatehtml': 35785,\n",
       " 'produced': 38173,\n",
       " 'processing': 38096,\n",
       " 'knit2html': 28045,\n",
       " 'package3': 35799,\n",
       " 'figure': 20894,\n",
       " 'placed': 36979,\n",
       " 'directory': 17212,\n",
       " 'default': 16401,\n",
       " 'overrode': 35715,\n",
       " 'repository4': 40444,\n",
       " 'github5': 22795,\n",
       " 'sitein': 43443,\n",
       " 'addition': 7092,\n",
       " 'willneed': 51387,\n",
       " '40': 4919,\n",
       " 'character': 12449,\n",
       " 'hash': 23982,\n",
       " 'string': 45342,\n",
       " 'from09': 21910,\n",
       " 'letter': 28842,\n",
       " 'af': 7300,\n",
       " 'identifies': 25184,\n",
       " 'thatcontains': 46892,\n",
       " 'want': 50793,\n",
       " 'thisin': 47192,\n",
       " 'following1': 21448,\n",
       " 'go': 23011,\n",
       " 'page': 35867,\n",
       " 'assignment2': 8903,\n",
       " 'click': 13088,\n",
       " 'commits': 13644,\n",
       " 'link': 29190,\n",
       " '10': 1194,\n",
       " 'say': 41875,\n",
       " 'commits3': 13645,\n",
       " 'see': 42344,\n",
       " 'list': 30054,\n",
       " 'recent': 39767,\n",
       " 'top': 47923,\n",
       " 'represents': 40495,\n",
       " 'copy': 14604,\n",
       " 'clipboard': 13114,\n",
       " 'button': 11424,\n",
       " 'right': 41009,\n",
       " 'hand': 23780,\n",
       " 'side': 43157,\n",
       " 'appear': 8232,\n",
       " 'hover': 24766,\n",
       " 'paste': 36227,\n",
       " 'hasha': 23983,\n",
       " 'valid': 49971,\n",
       " 'exampler7c376cc5447f11537f8740af8e07d6facc3d9645': 19871,\n",
       " 'science': 42036,\n",
       " 'specializationthese': 44407,\n",
       " 'material': 31307,\n",
       " 'john': 27408,\n",
       " 'hopkins': 24646,\n",
       " 'specialization': 44406,\n",
       " 'courseramaterials': 14873,\n",
       " 'development': 16914,\n",
       " 'subject': 45535,\n",
       " 'change': 12385,\n",
       " 'contributor': 14467,\n",
       " 'brian': 10947,\n",
       " 'caffo': 11632,\n",
       " 'jeff': 27266,\n",
       " 'leek': 28760,\n",
       " 'roger': 41202,\n",
       " 'peng': 36510,\n",
       " 'nick': 33728,\n",
       " 'carchedi': 11847,\n",
       " 'sean': 42235,\n",
       " 'kross': 28140,\n",
       " 'licensethese': 29031,\n",
       " 'creative': 15099,\n",
       " 'common': 13660,\n",
       " 'attribution': 9184,\n",
       " 'noncommercial': 33936,\n",
       " 'sharealike': 42861,\n",
       " 'ccncsa': 12190,\n",
       " 'license': 28998,\n",
       " 'nlpdatalogocitations487redsvgdatalogohomee4babae7949fe6b5aae8b4b9e68c87e58d97brightgreensvgdatalogoe78c8ee98081e997a8cvorangesvg': 33796,\n",
       " 'powerful': 37538,\n",
       " 'nlpweapon': 33805,\n",
       " 'arsenal': 8695,\n",
       " 'nlp': 33790,\n",
       " 'nlpnlpgithubstarstarwatchforkheartheartheart': 33801,\n",
       " 'eggplant': 18756,\n",
       " 'cherry': 12604,\n",
       " 'pear': 36466,\n",
       " 'tangerine': 46376,\n",
       " 'nbsp': 33419,\n",
       " 'nbspsunflower': 33433,\n",
       " 'strawberrymelon': 45289,\n",
       " 'tomato': 47857,\n",
       " 'pineapple': 36869,\n",
       " 'starstarstarstarstarstarstarstarstarstar': 44847,\n",
       " 'wainshinechinesenamescorpus': 50718,\n",
       " 'chinesewordvectorsgithub': 12763,\n",
       " 'repo': 40395,\n",
       " 'ptt': 38562,\n",
       " 'json': 27551,\n",
       " 'httpspanbaiducoms1quskcfwz7tg1dkabldz1a': 24895,\n",
       " '2dva': 4419,\n",
       " '3ghtmljsonnameaccountidtitlecontent': 4882,\n",
       " 'leaderboardstateoftheart': 28688,\n",
       " 'asr': 8851,\n",
       " 'litbanknlp': 30109,\n",
       " '100': 1195,\n",
       " 'ulmfit': 48825,\n",
       " 'githubgithub': 22860,\n",
       " '5809385800': 5528,\n",
       " '851620135mgithub': 6315,\n",
       " 'nlp17gb9mb23': 33791,\n",
       " 'gbit': 22329,\n",
       " '700000': 5947,\n",
       " 'couplet': 14859,\n",
       " '70': 5943,\n",
       " '42gbjdcsdd': 5051,\n",
       " 'github70': 22797,\n",
       " '4homepagehttphltsudaeducnindexphpnlpcc2019sharedtaskgithub': 5275,\n",
       " 'fake': 20479,\n",
       " 'news': 33655,\n",
       " 'corpus': 14693,\n",
       " 'baseline': 9779,\n",
       " 'cluedatasetsearch': 13270,\n",
       " 'nlpnlpnlp': 33802,\n",
       " '139m': 1897,\n",
       " 'paper': 36012,\n",
       " 'githubopenclap': 22887,\n",
       " 'bert': 10114,\n",
       " 'drcdsquadcmrc': 18245,\n",
       " '2018squadgithub': 3231,\n",
       " 'dakshina': 15901,\n",
       " 'githubopus100': 22888,\n",
       " 'githubhttpsquantumstatcomdatasetdatasethtml': 22871,\n",
       " 'github70githubgithubcolddatesetpaper': 22798,\n",
       " 'textfilter': 46817,\n",
       " 'observersstextfilter': 34481,\n",
       " 'coconlp': 13353,\n",
       " 'vngithub': 50595,\n",
       " 'kfcdchaizi': 27891,\n",
       " '0400704566541': 284,\n",
       " '037006739587': 278,\n",
       " 'rainarchsentibridge': 39247,\n",
       " 'dongxiexidianchinese': 17981,\n",
       " 'pythonpinyin': 38782,\n",
       " 'mozillazgpythonpinyin': 32854,\n",
       " 'zhtools': 53081,\n",
       " 'skydarknstools': 43553,\n",
       " 'wo': 51695,\n",
       " 'ni': 33714,\n",
       " 'tinyfoolchinesewithenglishchinesedictionary': 47673,\n",
       " 'guotong1988chinesedictionary': 23625,\n",
       " 'wordninja': 51738,\n",
       " 'thu': 47402,\n",
       " '856': 6320,\n",
       " '28020w13github': 4291,\n",
       " 'httpspanbaiducoms1mxzonalgeaw0txzzdaiyq': 24894,\n",
       " 'pea6bilstm': 36455,\n",
       " 'crf': 15121,\n",
       " 'kera': 27785,\n",
       " 'universal': 49073,\n",
       " 'transformer': 48191,\n",
       " 'java': 27182,\n",
       " 'chinesexinhuaapi': 12764,\n",
       " 'spacy': 44352,\n",
       " 'parser': 36137,\n",
       " 'ner': 33548,\n",
       " 'packagespacyspacy': 35824,\n",
       " 'synonym': 46019,\n",
       " 'harvesttext': 23975,\n",
       " 'word2word623564': 51734,\n",
       " 'github103976sqlcsvexcelgithub': 22789,\n",
       " '186': 2445,\n",
       " 'featurizer': 20736,\n",
       " 'charfeaturizer': 12475,\n",
       " 'mecabpython': 31539,\n",
       " 'githubg2pc': 22858,\n",
       " 'ssc': 44688,\n",
       " 'sound': 44040,\n",
       " 'shape': 42854,\n",
       " '1version': 2876,\n",
       " '2blogintroductionhttpsblogcsdnnetchndataarticledetails41114771': 4399,\n",
       " 'tokenizer': 47835,\n",
       " 'tokenizers': 47836,\n",
       " 'token2indexpytorchtensorflowgithub': 47834,\n",
       " 'github68916githubgithubcomliuhuanyongdomainwordsdict': 22796,\n",
       " 'bmlistgithub': 10551,\n",
       " 'bertslideslink': 10131,\n",
       " 'githubbert': 22817,\n",
       " 'tutorial': 48582,\n",
       " 'pytorch': 38799,\n",
       " 'pytorchgithubbertbert': 38804,\n",
       " 'bertelmo': 10118,\n",
       " 'githubhttpsjalammargithubioillustratedbertbert': 22870,\n",
       " 'pretrained': 37879,\n",
       " 'model': 32422,\n",
       " 'downstream': 18118,\n",
       " 'application': 8270,\n",
       " 'ernie': 19465,\n",
       " 'githubkashgarigpt2github': 22875,\n",
       " 'facebook': 20388,\n",
       " 'lama': 28260,\n",
       " 'transformerxlbertelmogptgithub': 48198,\n",
       " 'gpt2github': 23251,\n",
       " 'xlmfacebook': 52449,\n",
       " 'githubalbertgithub': 22803,\n",
       " '20tensorflow': 3899,\n",
       " '20': 2885,\n",
       " 'gpt2': 23250,\n",
       " 'roberta': 41149,\n",
       " 'xlm': 52448,\n",
       " 'distilbert': 17433,\n",
       " 'xlnet': 52451,\n",
       " '833102': 6298,\n",
       " 'github8bertgithubhttpswwwmsracnzhcnnewsfeaturesbert': 22799,\n",
       " 'roberta138gbroberta': 41150,\n",
       " 'electrea': 18866,\n",
       " 'pretrain': 37878,\n",
       " 'chinese': 12739,\n",
       " 'albertchinesener': 7512,\n",
       " 'albertner': 7514,\n",
       " 'electra': 18865,\n",
       " 'transformersbert': 48194,\n",
       " 'bart': 9745,\n",
       " 'xlmrobertagithub': 52450,\n",
       " 'tensorflow': 46619,\n",
       " 'hub': 24913,\n",
       " '40link': 4974,\n",
       " 'uer': 48771,\n",
       " 'bertgptelmo': 10120,\n",
       " 'language': 28293,\n",
       " 'service': 42665,\n",
       " 'lmaasgithubgptneox20b200githubcsl': 30223,\n",
       " '396209': 4828,\n",
       " 'csl': 15251,\n",
       " 'python': 38749,\n",
       " 'package': 35798,\n",
       " 'keyphrase': 27876,\n",
       " 'pke': 36952,\n",
       " 'blink': 10465,\n",
       " 'bertcrf': 10117,\n",
       " 'githublatticelstmgithub': 22877,\n",
       " 'pythongithub': 38770,\n",
       " 'tensorflowbert': 46620,\n",
       " 'entity': 19335,\n",
       " 'relation': 40167,\n",
       " 'extraction': 20313,\n",
       " 'based': 9774,\n",
       " 'tensorflowbert2019schema': 46621,\n",
       " 'knowledge': 28060,\n",
       " 'ske': 43513,\n",
       " '2019': 3239,\n",
       " 'neuroner': 33620,\n",
       " 'bertner': 10126,\n",
       " 'bertgithub': 10119,\n",
       " 'bertkashgari': 10124,\n",
       " 'kashgari': 27711,\n",
       " 'githubcoconlp': 22824,\n",
       " 'rake': 39257,\n",
       " 'githubmicrosoftgithub': 22881,\n",
       " 'githubnergithub': 22883,\n",
       " 'githubchinesekeyphraseextractor': 22821,\n",
       " 'ckpea': 12962,\n",
       " 'tool': 47887,\n",
       " 'bertnerpytorchbertnergithub': 10129,\n",
       " 'xlore': 52459,\n",
       " 'repogithub': 40405,\n",
       " 'githubampligraph': 22804,\n",
       " 'pythongithubgithub': 38771,\n",
       " 'githubzincbase': 22910,\n",
       " 'github132': 22790,\n",
       " 'linkhttpopenkgcncokg19': 29336,\n",
       " 'linkgithub': 29331,\n",
       " '50': 5311,\n",
       " 'github14': 22791,\n",
       " 'githubjiagu': 22874,\n",
       " 'bilstm': 10267,\n",
       " 'medicalner': 31578,\n",
       " 'libkgegithub': 28943,\n",
       " 'mongodb81005800jiebademo': 32618,\n",
       " 'dstlr': 18323,\n",
       " 'covid19': 14903,\n",
       " 'dglke': 17035,\n",
       " 'githubmethod': 22880,\n",
       " 'datalink': 16010,\n",
       " 'texar': 46791,\n",
       " 'toolkit': 47901,\n",
       " 'text': 46796,\n",
       " 'generation': 22533,\n",
       " 'beyond': 10177,\n",
       " 'ehud': 18794,\n",
       " 'reiter': 40141,\n",
       " 'linknlg': 29442,\n",
       " 'githubbleurt': 22819,\n",
       " 'link70': 29197,\n",
       " 'transformerhacker': 48192,\n",
       " 'githubsql': 22901,\n",
       " 'githubtextfooler': 22902,\n",
       " 'githubsimbert': 22896,\n",
       " 'unilmbert': 49022,\n",
       " 'githubgpt2github': 22865,\n",
       " 'githubtextteaser': 22904,\n",
       " 'colab': 13445,\n",
       " 'robot': 41175,\n",
       " 'qingyunqingyun': 38983,\n",
       " 'githubhttpswwwownthinkcomheadern30qaamodelforretrivalchatbot': 22873,\n",
       " 'retreival': 40811,\n",
       " 'chatbot': 12504,\n",
       " 'convlabgithub': 14548,\n",
       " 'rasa': 39317,\n",
       " 'miningzhidaoqacorpus580580github': 32148,\n",
       " 'gpt2gpt2chitchat': 23252,\n",
       " 'leaderboardsdatasetspapers': 28687,\n",
       " 'chatbotlist': 12509,\n",
       " 'medical': 31577,\n",
       " 'dialogue': 17057,\n",
       " '110400github': 1468,\n",
       " 'crosswozpaper': 15190,\n",
       " '2020dstc9': 3589,\n",
       " '2020github': 3591,\n",
       " 'quorat5paraphrase': 39140,\n",
       " 'githubgoogletaskmaster2': 22863,\n",
       " 'githubhaystackqa': 22867,\n",
       " 'amazon': 7758,\n",
       " 'githubwebqadureaderalbert': 22907,\n",
       " 'qa': 38821,\n",
       " 'commonsenseqaqa': 13665,\n",
       " 'medquad': 31592,\n",
       " 'albertelectra': 7513,\n",
       " '14w': 2047,\n",
       " 'githubpythongithub': 22892,\n",
       " 'typo': 48704,\n",
       " 'corpusgithub': 14699,\n",
       " 'githubbertpuncbert': 22818,\n",
       " 'spell': 44464,\n",
       " 'checking': 12545,\n",
       " 'csc': 15242,\n",
       " 'grammatical': 23290,\n",
       " 'error': 19476,\n",
       " 'correction': 14706,\n",
       " 'gecgithublink': 22422,\n",
       " '1github': 2791,\n",
       " 'thchs30datathchs30tgzopenslrdatathchs30tgz': 46919,\n",
       " 'testnoisetgzopenslrtestnoisetgz': 46741,\n",
       " 'resourcetgzopenslrresourcetgzfree': 40662,\n",
       " 'st': 44737,\n",
       " 'mandarin': 31049,\n",
       " 'corpusfree': 14698,\n",
       " 'corpusaishell1': 14695,\n",
       " 'openslraishell1': 35129,\n",
       " 'primewords': 37929,\n",
       " '1openslrprimewords': 2827,\n",
       " 'githubcommon': 22834,\n",
       " 'voice420001400github': 50622,\n",
       " 'speechaligner': 44446,\n",
       " 'githubh': 22866,\n",
       " 'githubmasr': 22878,\n",
       " 'mosnet': 32744,\n",
       " 'bsseval': 11076,\n",
       " 'stoi': 45210,\n",
       " 'pesq': 36669,\n",
       " 'srmr': 44671,\n",
       " 'githubcovostfacebook': 22853,\n",
       " '11github': 1584,\n",
       " 'parakeetpaddlepaddle': 36030,\n",
       " 'covostfacebook': 14911,\n",
       " 'visqol': 50540,\n",
       " 'zhrtvc': 53080,\n",
       " 'githubaukit': 22814,\n",
       " 'githubphkit': 22890,\n",
       " 'zhvoice': 53092,\n",
       " '832009001300': 6295,\n",
       " 'audio': 9201,\n",
       " 'audioset': 9206,\n",
       " 'pylaia': 38720,\n",
       " 'docsearch': 17818,\n",
       " 'githubfdfgen': 22855,\n",
       " 'pdf': 36428,\n",
       " 'pdfx': 36447,\n",
       " 'invoice2data': 26603,\n",
       " 'pdfgithub': 36433,\n",
       " 'pdfminer': 36435,\n",
       " 'pdfminerpdfpdfhtmlpdf': 36436,\n",
       " 'linkpypdf2pypdf': 29470,\n",
       " '2python': 4464,\n",
       " 'pdfpdfpdfpdflink': 36439,\n",
       " 'pypdf2': 38729,\n",
       " 'pypdf': 38728,\n",
       " 'pdfpdfpdfpdf': 36438,\n",
       " 'linkreportlab': 29478,\n",
       " 'reportlabpdf': 40428,\n",
       " 'pdfpython5linuxwikipedia': 36441,\n",
       " 'simpdfpythonpdf': 43305,\n",
       " 'githubpdfdiff': 22889,\n",
       " 'pdfdiff': 36430,\n",
       " 'unet': 48981,\n",
       " 'pdftabextractocrlink': 36446,\n",
       " 'tabulapy': 46298,\n",
       " 'pdfpandasdataframejavapython': 36437,\n",
       " 'camelot': 11727,\n",
       " 'pdfplumber': 36440,\n",
       " 'publaynet': 38572,\n",
       " 'gan': 22267,\n",
       " 'githubcarefreelearnpytorchautomlgithub': 22820,\n",
       " 'tabert': 46268,\n",
       " 'paperhttpsscontenthkt11xxfbcdnnetvt39856261067088995977651078102301899215558892880563npdfnccat107ncsidae5e01ncohc4sn3tjwewsiax8ilibdnchtscontenthkt11xxoheccb9795f027ff63be61ff4a5e337c02oe5f316505': 36015,\n",
       " 'awesometablerecognition': 9397,\n",
       " 'qamatchzoo': 38822,\n",
       " 'githubsimilarity': 22897,\n",
       " 'javagithub': 27198,\n",
       " 'hownetgihtub': 24792,\n",
       " 'siamese': 43138,\n",
       " 'bilstm10': 10268,\n",
       " 'nlpedagithub': 33797,\n",
       " 'nlplink': 33799,\n",
       " 'email': 18938,\n",
       " 'phonenumber': 36731,\n",
       " 'idcardspattern': 25157,\n",
       " '19d512d301910120191209301d309xxids': 2693,\n",
       " 'refindallidcardspattern': 39951,\n",
       " 'flags0': 21208,\n",
       " 'ip2505204d01d219d2505204d01d219d2505204d01d219d2505204d01d219dqq': 26674,\n",
       " '1909511': 2496,\n",
       " '09718': 473,\n",
       " 'azaz09u4e00u9fa5': 9433,\n",
       " 'bertlink': 10125,\n",
       " 'deepmatch': 16394,\n",
       " 'githubwwsearch': 22908,\n",
       " 'aili': 7440,\n",
       " 'fastest': 20616,\n",
       " 'inmemory': 25985,\n",
       " 'index': 25690,\n",
       " 'east': 18572,\n",
       " 'rapidfuzza': 39309,\n",
       " 'fast': 20606,\n",
       " 'matching': 31304,\n",
       " 'library': 28962,\n",
       " 'similarity': 43265,\n",
       " 'fuzzywuzzygithub': 22192,\n",
       " 'allennlp': 7615,\n",
       " 'githubawesomenlpsentimentanalysis': 22816,\n",
       " 'githubhttpsdeveloperaliyuncomarticle761513utmcontentg1000124809': 22869,\n",
       " 'pytorchbertace': 38801,\n",
       " '2005': 2924,\n",
       " 'nllb200nllblink': 33789,\n",
       " 'baidu': 9583,\n",
       " 'inkhttpspanbaiducoms1gkpmj7kvffwpjyvsvaaacode': 25978,\n",
       " 'a0qq': 6578,\n",
       " 'textcluster': 46813,\n",
       " 'short': 43038,\n",
       " 'cluster': 13273,\n",
       " 'neuralnlpneuralclassifiergithub': 33618,\n",
       " 'graphbrainai': 23311,\n",
       " 'pdfhttpscdn1sphharvardeduwpcontentuploadssites1268201910cihernanrobins23oct19pdf': 36434,\n",
       " 'textattack': 46806,\n",
       " 'openbackdoor': 35097,\n",
       " 'openbackdoorpythonpytorch': 35098,\n",
       " 'scattertext': 41971,\n",
       " 'whatlies': 51199,\n",
       " 'spacyhttpsspacyiouniverseprojectwhatlies': 44353,\n",
       " 'pyss3aiss3': 38746,\n",
       " '3d': 4861,\n",
       " 'githubattnvisgpt2berttransformer': 22813,\n",
       " 'githubtexthero': 22903,\n",
       " 'brat': 10900,\n",
       " 'rapid': 39308,\n",
       " 'annotation': 7977,\n",
       " 'poplar': 37352,\n",
       " 'lida': 29045,\n",
       " 'doccano': 17794,\n",
       " 'datasaurai': 16024,\n",
       " 'langid': 28291,\n",
       " '97': 6515,\n",
       " 'langdetect': 28288,\n",
       " 'jiebajiebahanlp': 27340,\n",
       " 'hanlp': 23846,\n",
       " 'nlp4hannernhmm': 33793,\n",
       " 'pytorchbertgithub': 38802,\n",
       " 'nlp4han': 33792,\n",
       " 'nernhmm': 33551,\n",
       " 'jiebafast': 27339,\n",
       " 'jieba': 27337,\n",
       " 'stanfordnlp': 44827,\n",
       " 'prenlpgithub': 37807,\n",
       " 'nlpword': 33806,\n",
       " 'embeddingnertext': 18967,\n",
       " 'classificatintext': 13010,\n",
       " 'generationtext': 22537,\n",
       " 'similaritynlpkerastensorflowgithub': 43268,\n",
       " 'pythonnlp': 38779,\n",
       " 'fortepipeline': 21685,\n",
       " 'stanzanlp': 44831,\n",
       " 'fancynlp': 20560,\n",
       " 'dssmpipeline': 18321,\n",
       " 'nlpgnngithub': 33798,\n",
       " 'macadam': 30831,\n",
       " 'tensorflowkerasbert4keras': 46624,\n",
       " 'lineflownlp': 29154,\n",
       " 'githubarabicapythongithubpython': 22808,\n",
       " 'smsboomgithubgithubcomwhalefellsmsboom': 43766,\n",
       " 'phunterlauwangfengrnn': 36765,\n",
       " 'coupletai': 14860,\n",
       " 'cnnbilstmattention': 13322,\n",
       " 'cope': 14589,\n",
       " 'paper2gui': 36013,\n",
       " 'aiapp18aiocr': 7429,\n",
       " 'paperpython': 36017,\n",
       " 'homepagegitee': 24585,\n",
       " 'link3dlink': 29196,\n",
       " 'cs224nlinkhttpwebstanfordeduclasscs224n': 15239,\n",
       " 'natural': 33380,\n",
       " 'processingby': 38098,\n",
       " 'jacob': 27106,\n",
       " 'eisenstein': 18814,\n",
       " 'mlnlp': 32331,\n",
       " 'learningnlp': 28723,\n",
       " '2019nlp': 3349,\n",
       " 'downloadhttpspanbaiducoms1h5gepuhvy1hkuvc32eex4w': 18096,\n",
       " 'nlprecipes': 33803,\n",
       " 'transfer': 48178,\n",
       " 'learning': 28719,\n",
       " 'youtube': 52928,\n",
       " 'nlptop': 33804,\n",
       " '20197': 3341,\n",
       " 'bdci2019': 9880,\n",
       " 'githubgithubcomjm199504financialknowledgegraphs': 22861,\n",
       " 'githubspacy': 22899,\n",
       " 'githubhttpswwwaminercndatacovid19github': 22872,\n",
       " 'blackstonespacy': 10419,\n",
       " 'pipelinenlpgithub': 36901,\n",
       " 'phone': 36723,\n",
       " 'ls0fphone': 30631,\n",
       " 'aftershipphone': 7343,\n",
       " 'ngender': 33693,\n",
       " 'observerssngendernlp': 34480,\n",
       " 'ppt': 37578,\n",
       " 'comparxiv': 13726,\n",
       " 'arxiv': 8724,\n",
       " 'pypihttpspypiorgprojectcomparxiv': 38731,\n",
       " 'chameleon': 12371,\n",
       " 'itbertcoconlpxlorenlucs224n': 26927,\n",
       " 'microsoftapispacy': 31960,\n",
       " 'voicebertkeyphrasepke4cnocrocrpython3nlpspeechaligner': 50623,\n",
       " 'ampligraph': 7807,\n",
       " 'pythonscattertext': 38788,\n",
       " 'pythonbert': 38760,\n",
       " 'ernienlpsynonymsharvesttextword2wordpython623564asrkashgarigpt2textteaser': 19466,\n",
       " '14wandsiamese': 2048,\n",
       " 'bilstmtransformerhacker': 10269,\n",
       " 'newsbertlitbanknlp100facebook': 33657,\n",
       " 'lamatransformerxlbertelmogptcommonsenseqaqa': 28261,\n",
       " 'pptsqlnlpedanlp': 37579,\n",
       " 'mongodbulmfit': 32621,\n",
       " 'qingyun': 38982,\n",
       " 'seqganmasr': 42581,\n",
       " 'pythonbertconvlabrasatensorflowbertnlptopopenclapuerg2pczincbase': 38761,\n",
       " ...}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize count vectorizer object\n",
    "# use your own tokenize function\n",
    "vect = CountVectorizer()\n",
    "# get counts of each token (word) in text data\n",
    "X = vect.fit_transform(df.lemmatized)\n",
    "# convert sparse matrix to numpy array to view\n",
    "X.toarray()\n",
    "# view token vocabulary and counts\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "825b9b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# initialize tf-idf vectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# compute bag of word counts and tf-idf values\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# convert sparse matrix to numpy array to view\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232880e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# initialize tf-idf transformer object\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "# use counts from count vectorizer results to compute tf-idf values\n",
    "tfidf = transformer.fit_transform(X)\n",
    "# convert sparse matrix to numpy array to view\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d9b142e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'zyglis', 'zyxelp870hnu51bbssid', 'zyxq'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8635dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa199fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vectorizer2.fit_transform(df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d56bee5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00 00', '00 00bx', '00 00cr0', ..., 'zyglis 2019',\n",
       "       'zyxelp870hnu51bbssid fcf528tplinktplinkxxxxxxtlwa7510nbssid',\n",
       "       'zyxq gtking'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56743b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m count_vect \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcount_vect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary_\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f50d95e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2492493230.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [63]\u001b[0;36m\u001b[0m\n\u001b[0;31m    [word]a = (' '.join(df[df.langugae == [word].text))\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for word in df.language:\n",
    "    [word]a = (' '.join(df[df.langugae == [word].text\n",
    "    [word]_freq = pd.Series([word]a).value_counts()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f15959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = clean(' '.join(df.readme_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "240fce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introduction',\n",
       " 'assignment',\n",
       " 'us',\n",
       " 'data',\n",
       " 'hrefhttparchiveicsuciedumluc',\n",
       " 'irvine',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'repositorya',\n",
       " 'popular',\n",
       " 'repository',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'datasets',\n",
       " 'particular',\n",
       " 'using',\n",
       " 'individual',\n",
       " 'household',\n",
       " 'electric',\n",
       " 'power',\n",
       " 'consumption',\n",
       " 'data',\n",
       " 'set',\n",
       " 'made',\n",
       " 'available',\n",
       " 'course',\n",
       " 'web',\n",
       " 'site',\n",
       " 'bdatasetb',\n",
       " 'hrefhttpsd396qusza40orccloudfrontnetexdata2fdata2fhousehold_power_consumptionzipelectric',\n",
       " 'power',\n",
       " 'consumptiona',\n",
       " '20mb',\n",
       " 'bdescriptionb',\n",
       " 'measurement',\n",
       " 'electric',\n",
       " 'power',\n",
       " 'consumption',\n",
       " 'one',\n",
       " 'household',\n",
       " 'oneminute',\n",
       " 'sampling',\n",
       " 'rate',\n",
       " 'period',\n",
       " 'almost',\n",
       " '4',\n",
       " 'year',\n",
       " 'different',\n",
       " 'electrical',\n",
       " 'quantity',\n",
       " 'submetering',\n",
       " 'value',\n",
       " 'available',\n",
       " 'following',\n",
       " 'description',\n",
       " '9',\n",
       " 'variable',\n",
       " 'dataset',\n",
       " 'taken',\n",
       " 'hrefhttpsarchiveicsuciedumldatasetsindividualhouseholdelectricpowerconsumptionuci',\n",
       " 'web',\n",
       " 'sitea',\n",
       " 'ol',\n",
       " 'libdateb',\n",
       " 'date',\n",
       " 'format',\n",
       " 'ddmmyyyy',\n",
       " 'li',\n",
       " 'libtimeb',\n",
       " 'time',\n",
       " 'format',\n",
       " 'hhmmss',\n",
       " 'li',\n",
       " 'libglobal_active_powerb',\n",
       " 'household',\n",
       " 'global',\n",
       " 'minuteaveraged',\n",
       " 'active',\n",
       " 'power',\n",
       " 'kilowatt',\n",
       " 'li',\n",
       " 'libglobal_reactive_powerb',\n",
       " 'household',\n",
       " 'global',\n",
       " 'minuteaveraged',\n",
       " 'reactive',\n",
       " 'power',\n",
       " 'kilowatt',\n",
       " 'li',\n",
       " 'libvoltageb',\n",
       " 'minuteaveraged',\n",
       " 'voltage',\n",
       " 'volt',\n",
       " 'li',\n",
       " 'libglobal_intensityb',\n",
       " 'household',\n",
       " 'global',\n",
       " 'minuteaveraged',\n",
       " 'current',\n",
       " 'intensity',\n",
       " 'ampere',\n",
       " 'li',\n",
       " 'libsub_metering_1b',\n",
       " 'energy',\n",
       " 'submetering',\n",
       " '1',\n",
       " 'watthour',\n",
       " 'active',\n",
       " 'energy',\n",
       " 'corresponds',\n",
       " 'kitchen',\n",
       " 'containing',\n",
       " 'mainly',\n",
       " 'dishwasher',\n",
       " 'oven',\n",
       " 'microwave',\n",
       " 'hot',\n",
       " 'plate',\n",
       " 'electric',\n",
       " 'gas',\n",
       " 'powered',\n",
       " 'li',\n",
       " 'libsub_metering_2b',\n",
       " 'energy',\n",
       " 'submetering',\n",
       " 'watthour',\n",
       " 'active',\n",
       " 'energy',\n",
       " 'corresponds',\n",
       " 'laundry',\n",
       " 'room',\n",
       " 'containing',\n",
       " 'washingmachine',\n",
       " 'tumbledrier',\n",
       " 'refrigerator',\n",
       " 'light',\n",
       " 'li',\n",
       " 'libsub_metering_3b',\n",
       " 'energy',\n",
       " 'submetering',\n",
       " '3',\n",
       " 'watthour',\n",
       " 'active',\n",
       " 'energy',\n",
       " 'corresponds',\n",
       " 'electric',\n",
       " 'waterheater',\n",
       " 'airconditionerli',\n",
       " 'ol',\n",
       " 'loading',\n",
       " 'data',\n",
       " 'loading',\n",
       " 'dataset',\n",
       " 'please',\n",
       " 'consider',\n",
       " 'following',\n",
       " 'dataset',\n",
       " '2075259',\n",
       " 'row',\n",
       " '9',\n",
       " 'column',\n",
       " 'first',\n",
       " 'calculate',\n",
       " 'rough',\n",
       " 'estimate',\n",
       " 'much',\n",
       " 'memory',\n",
       " 'dataset',\n",
       " 'require',\n",
       " 'memory',\n",
       " 'reading',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'computer',\n",
       " 'enough',\n",
       " 'memory',\n",
       " 'modern',\n",
       " 'computer',\n",
       " 'fine',\n",
       " 'using',\n",
       " 'data',\n",
       " 'date',\n",
       " '20070201',\n",
       " '20070202',\n",
       " 'one',\n",
       " 'alternative',\n",
       " 'read',\n",
       " 'data',\n",
       " 'date',\n",
       " 'rather',\n",
       " 'reading',\n",
       " 'entire',\n",
       " 'dataset',\n",
       " 'subsetting',\n",
       " 'date',\n",
       " 'may',\n",
       " 'find',\n",
       " 'useful',\n",
       " 'convert',\n",
       " 'date',\n",
       " 'time',\n",
       " 'variable',\n",
       " 'datetime',\n",
       " 'class',\n",
       " 'using',\n",
       " 'strptime',\n",
       " 'asdate',\n",
       " 'function',\n",
       " 'note',\n",
       " 'dataset',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'coded',\n",
       " 'making',\n",
       " 'plot',\n",
       " 'overall',\n",
       " 'goal',\n",
       " 'simply',\n",
       " 'examine',\n",
       " 'household',\n",
       " 'energy',\n",
       " 'usage',\n",
       " 'varies',\n",
       " '2day',\n",
       " 'period',\n",
       " 'february',\n",
       " '2007',\n",
       " 'task',\n",
       " 'reconstruct',\n",
       " 'following',\n",
       " 'plot',\n",
       " 'constructed',\n",
       " 'using',\n",
       " 'base',\n",
       " 'plotting',\n",
       " 'system',\n",
       " 'first',\n",
       " 'need',\n",
       " 'fork',\n",
       " 'clone',\n",
       " 'following',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'httpsgithubcomrdpengexdata_plotting1httpsgithubcomrdpengexdata_plotting1',\n",
       " 'plot',\n",
       " 'construct',\n",
       " 'plot',\n",
       " 'save',\n",
       " 'png',\n",
       " 'file',\n",
       " 'width',\n",
       " '480',\n",
       " 'pixel',\n",
       " 'height',\n",
       " '480',\n",
       " 'pixel',\n",
       " 'name',\n",
       " 'plot',\n",
       " 'file',\n",
       " 'plot1png',\n",
       " 'plot2png',\n",
       " 'etc',\n",
       " 'create',\n",
       " 'separate',\n",
       " 'code',\n",
       " 'file',\n",
       " 'plot1r',\n",
       " 'plot2r',\n",
       " 'etc',\n",
       " 'construct',\n",
       " 'corresponding',\n",
       " 'plot',\n",
       " 'ie',\n",
       " 'code',\n",
       " 'plot1r',\n",
       " 'construct',\n",
       " 'plot1png',\n",
       " 'plot',\n",
       " 'code',\n",
       " 'file',\n",
       " 'include',\n",
       " 'code',\n",
       " 'reading',\n",
       " 'data',\n",
       " 'plot',\n",
       " 'fully',\n",
       " 'reproduced',\n",
       " 'also',\n",
       " 'include',\n",
       " 'code',\n",
       " 'creates',\n",
       " 'png',\n",
       " 'file',\n",
       " 'add',\n",
       " 'png',\n",
       " 'file',\n",
       " 'code',\n",
       " 'file',\n",
       " 'git',\n",
       " 'repository',\n",
       " 'finished',\n",
       " 'assignment',\n",
       " 'push',\n",
       " 'git',\n",
       " 'repository',\n",
       " 'github',\n",
       " 'github',\n",
       " 'version',\n",
       " 'repository',\n",
       " 'date',\n",
       " 'four',\n",
       " 'png',\n",
       " 'file',\n",
       " 'four',\n",
       " 'code',\n",
       " 'file',\n",
       " 'four',\n",
       " 'plot',\n",
       " 'need',\n",
       " 'construct',\n",
       " 'shown',\n",
       " 'plot',\n",
       " '1',\n",
       " 'plot',\n",
       " 'chunk',\n",
       " 'unnamedchunk2figureunnamedchunk2png',\n",
       " 'plot',\n",
       " 'plot',\n",
       " 'chunk',\n",
       " 'unnamedchunk3figureunnamedchunk3png',\n",
       " 'plot',\n",
       " '3',\n",
       " 'plot',\n",
       " 'chunk',\n",
       " 'unnamedchunk4figureunnamedchunk4png',\n",
       " 'plot',\n",
       " '4',\n",
       " 'plot',\n",
       " 'chunk',\n",
       " 'unnamedchunk5figureunnamedchunk5png',\n",
       " 'introduction',\n",
       " 'possible',\n",
       " 'collect',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'data',\n",
       " 'personal',\n",
       " 'movement',\n",
       " 'using',\n",
       " 'activity',\n",
       " 'monitoring',\n",
       " 'device',\n",
       " 'fitbithttpwwwfitbitcom',\n",
       " 'nike',\n",
       " 'fuelbandhttpwwwnikecomusen_uscnikeplusfuelband',\n",
       " 'jawbone',\n",
       " 'uphttpsjawbonecomup',\n",
       " 'type',\n",
       " 'device',\n",
       " 'part',\n",
       " 'quantified',\n",
       " 'self',\n",
       " 'movement',\n",
       " 'group',\n",
       " 'enthusiast',\n",
       " 'take',\n",
       " 'measurement',\n",
       " 'regularly',\n",
       " 'improve',\n",
       " 'health',\n",
       " 'find',\n",
       " 'pattern',\n",
       " 'behavior',\n",
       " 'tech',\n",
       " 'geek',\n",
       " 'data',\n",
       " 'remain',\n",
       " 'underutilized',\n",
       " 'raw',\n",
       " 'data',\n",
       " 'hard',\n",
       " 'obtain',\n",
       " 'lack',\n",
       " 'statistical',\n",
       " 'method',\n",
       " 'software',\n",
       " 'processing',\n",
       " 'interpreting',\n",
       " 'data',\n",
       " 'assignment',\n",
       " 'make',\n",
       " 'use',\n",
       " 'data',\n",
       " 'personal',\n",
       " 'activity',\n",
       " 'monitoring',\n",
       " 'device',\n",
       " 'device',\n",
       " 'collect',\n",
       " 'data',\n",
       " '5',\n",
       " 'minute',\n",
       " 'interval',\n",
       " 'day',\n",
       " 'data',\n",
       " 'consists',\n",
       " 'two',\n",
       " 'month',\n",
       " 'data',\n",
       " 'anonymous',\n",
       " 'individual',\n",
       " 'collected',\n",
       " 'month',\n",
       " 'october',\n",
       " 'november',\n",
       " '2012',\n",
       " 'include',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " '5',\n",
       " 'minute',\n",
       " 'interval',\n",
       " 'day',\n",
       " 'data',\n",
       " 'data',\n",
       " 'assignment',\n",
       " 'downloaded',\n",
       " 'course',\n",
       " 'web',\n",
       " 'site',\n",
       " 'dataset',\n",
       " 'activity',\n",
       " 'monitoring',\n",
       " 'datahttpsd396qusza40orccloudfrontnetrepdata2fdata2factivityzip',\n",
       " '52k',\n",
       " 'variable',\n",
       " 'included',\n",
       " 'dataset',\n",
       " 'step',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taking',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'coded',\n",
       " 'na',\n",
       " 'date',\n",
       " 'date',\n",
       " 'measurement',\n",
       " 'taken',\n",
       " 'yyyymmdd',\n",
       " 'format',\n",
       " 'interval',\n",
       " 'identifier',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'measurement',\n",
       " 'taken',\n",
       " 'dataset',\n",
       " 'stored',\n",
       " 'commaseparatedvalue',\n",
       " 'csv',\n",
       " 'file',\n",
       " 'total',\n",
       " '17568',\n",
       " 'observation',\n",
       " 'dataset',\n",
       " 'assignment',\n",
       " 'assignment',\n",
       " 'described',\n",
       " 'multiple',\n",
       " 'part',\n",
       " 'need',\n",
       " 'write',\n",
       " 'report',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'detailed',\n",
       " 'ultimately',\n",
       " 'need',\n",
       " 'complete',\n",
       " 'entire',\n",
       " 'assignment',\n",
       " 'single',\n",
       " 'markdown',\n",
       " 'document',\n",
       " 'processed',\n",
       " 'knitr',\n",
       " 'transformed',\n",
       " 'html',\n",
       " 'file',\n",
       " 'throughout',\n",
       " 'report',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'always',\n",
       " 'include',\n",
       " 'code',\n",
       " 'used',\n",
       " 'generate',\n",
       " 'output',\n",
       " 'present',\n",
       " 'writing',\n",
       " 'code',\n",
       " 'chunk',\n",
       " 'markdown',\n",
       " 'document',\n",
       " 'always',\n",
       " 'use',\n",
       " 'echo',\n",
       " 'true',\n",
       " 'someone',\n",
       " 'else',\n",
       " 'able',\n",
       " 'read',\n",
       " 'code',\n",
       " 'assignment',\n",
       " 'evaluated',\n",
       " 'via',\n",
       " 'peer',\n",
       " 'assessment',\n",
       " 'essential',\n",
       " 'peer',\n",
       " 'evaluator',\n",
       " 'able',\n",
       " 'review',\n",
       " 'code',\n",
       " 'analysis',\n",
       " 'plotting',\n",
       " 'aspect',\n",
       " 'assignment',\n",
       " 'feel',\n",
       " 'free',\n",
       " 'use',\n",
       " 'plotting',\n",
       " 'system',\n",
       " 'ie',\n",
       " 'base',\n",
       " 'lattice',\n",
       " 'ggplot2',\n",
       " 'forkclone',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'created',\n",
       " 'assignmenthttpgithubcomrdpengrepdata_peerassessment1',\n",
       " 'submit',\n",
       " 'assignment',\n",
       " 'pushing',\n",
       " 'completed',\n",
       " 'file',\n",
       " 'forked',\n",
       " 'repository',\n",
       " 'github',\n",
       " 'assignment',\n",
       " 'submission',\n",
       " 'consist',\n",
       " 'url',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'sha1',\n",
       " 'commit',\n",
       " 'id',\n",
       " 'repository',\n",
       " 'state',\n",
       " 'note',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'also',\n",
       " 'contains',\n",
       " 'dataset',\n",
       " 'assignment',\n",
       " 'download',\n",
       " 'data',\n",
       " 'separately',\n",
       " 'loading',\n",
       " 'preprocessing',\n",
       " 'data',\n",
       " 'show',\n",
       " 'code',\n",
       " 'needed',\n",
       " '1',\n",
       " 'load',\n",
       " 'data',\n",
       " 'ie',\n",
       " 'readcsv',\n",
       " 'processtransform',\n",
       " 'data',\n",
       " 'necessary',\n",
       " 'format',\n",
       " 'suitable',\n",
       " 'analysis',\n",
       " 'mean',\n",
       " 'total',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'per',\n",
       " 'day',\n",
       " 'part',\n",
       " 'assignment',\n",
       " 'ignore',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'dataset',\n",
       " '1',\n",
       " 'make',\n",
       " 'histogram',\n",
       " 'total',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'day',\n",
       " 'calculate',\n",
       " 'report',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'total',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'per',\n",
       " 'day',\n",
       " 'average',\n",
       " 'daily',\n",
       " 'activity',\n",
       " 'pattern',\n",
       " '1',\n",
       " 'make',\n",
       " 'time',\n",
       " 'series',\n",
       " 'plot',\n",
       " 'ie',\n",
       " 'type',\n",
       " 'l',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'xaxis',\n",
       " 'average',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'averaged',\n",
       " 'across',\n",
       " 'day',\n",
       " 'yaxis',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'average',\n",
       " 'across',\n",
       " 'day',\n",
       " 'dataset',\n",
       " 'contains',\n",
       " 'maximum',\n",
       " 'number',\n",
       " 'step',\n",
       " 'imputing',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'note',\n",
       " 'number',\n",
       " 'daysintervals',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'coded',\n",
       " 'na',\n",
       " 'presence',\n",
       " 'missing',\n",
       " 'day',\n",
       " 'may',\n",
       " 'introduce',\n",
       " 'bias',\n",
       " 'calculation',\n",
       " 'summary',\n",
       " 'data',\n",
       " '1',\n",
       " 'calculate',\n",
       " 'report',\n",
       " 'total',\n",
       " 'number',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'dataset',\n",
       " 'ie',\n",
       " 'total',\n",
       " 'number',\n",
       " 'row',\n",
       " 'na',\n",
       " 'devise',\n",
       " 'strategy',\n",
       " 'filling',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'dataset',\n",
       " 'strategy',\n",
       " 'need',\n",
       " 'sophisticated',\n",
       " 'example',\n",
       " 'could',\n",
       " 'use',\n",
       " 'meanmedian',\n",
       " 'day',\n",
       " 'mean',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'etc',\n",
       " '3',\n",
       " 'create',\n",
       " 'new',\n",
       " 'dataset',\n",
       " 'equal',\n",
       " 'original',\n",
       " 'dataset',\n",
       " 'missing',\n",
       " 'data',\n",
       " 'filled',\n",
       " '4',\n",
       " 'make',\n",
       " 'histogram',\n",
       " 'total',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'day',\n",
       " 'calculate',\n",
       " 'report',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'total',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'per',\n",
       " 'day',\n",
       " 'value',\n",
       " 'differ',\n",
       " 'estimate',\n",
       " 'first',\n",
       " 'part',\n",
       " 'assignment',\n",
       " 'impact',\n",
       " 'imputing',\n",
       " 'missing',\n",
       " 'data',\n",
       " 'estimate',\n",
       " 'total',\n",
       " 'daily',\n",
       " 'number',\n",
       " 'step',\n",
       " 'difference',\n",
       " 'activity',\n",
       " 'pattern',\n",
       " 'weekday',\n",
       " 'weekend',\n",
       " 'part',\n",
       " 'weekday',\n",
       " 'function',\n",
       " 'may',\n",
       " 'help',\n",
       " 'use',\n",
       " 'dataset',\n",
       " 'filledin',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'part',\n",
       " '1',\n",
       " 'create',\n",
       " 'new',\n",
       " 'factor',\n",
       " 'variable',\n",
       " 'dataset',\n",
       " 'two',\n",
       " 'level',\n",
       " 'weekday',\n",
       " 'weekend',\n",
       " 'indicating',\n",
       " 'whether',\n",
       " 'given',\n",
       " 'date',\n",
       " 'weekday',\n",
       " 'weekend',\n",
       " 'day',\n",
       " '1',\n",
       " 'make',\n",
       " 'panel',\n",
       " 'plot',\n",
       " 'containing',\n",
       " 'time',\n",
       " 'series',\n",
       " 'plot',\n",
       " 'ie',\n",
       " 'type',\n",
       " 'l',\n",
       " '5minute',\n",
       " 'interval',\n",
       " 'xaxis',\n",
       " 'average',\n",
       " 'number',\n",
       " 'step',\n",
       " 'taken',\n",
       " 'averaged',\n",
       " 'across',\n",
       " 'weekday',\n",
       " 'day',\n",
       " 'weekend',\n",
       " 'day',\n",
       " 'yaxis',\n",
       " 'plot',\n",
       " 'look',\n",
       " 'something',\n",
       " 'like',\n",
       " 'following',\n",
       " 'created',\n",
       " 'using',\n",
       " 'simulated',\n",
       " 'data',\n",
       " 'sample',\n",
       " 'panel',\n",
       " 'plotinstructions_figsample_panelplotpng',\n",
       " 'plot',\n",
       " 'look',\n",
       " 'different',\n",
       " 'one',\n",
       " 'using',\n",
       " 'activity',\n",
       " 'monitor',\n",
       " 'data',\n",
       " 'note',\n",
       " 'plot',\n",
       " 'made',\n",
       " 'using',\n",
       " 'lattice',\n",
       " 'system',\n",
       " 'make',\n",
       " 'version',\n",
       " 'plot',\n",
       " 'using',\n",
       " 'plotting',\n",
       " 'system',\n",
       " 'choose',\n",
       " 'submitting',\n",
       " 'assignment',\n",
       " 'submit',\n",
       " 'assignment',\n",
       " '1',\n",
       " 'commit',\n",
       " 'completed',\n",
       " 'pa1_templatermd',\n",
       " 'file',\n",
       " 'master',\n",
       " 'branch',\n",
       " 'git',\n",
       " 'repository',\n",
       " 'already',\n",
       " 'master',\n",
       " 'branch',\n",
       " 'unless',\n",
       " 'created',\n",
       " 'new',\n",
       " 'one',\n",
       " 'commit',\n",
       " 'pa1_templatemd',\n",
       " 'pa1_templatehtml',\n",
       " 'file',\n",
       " 'produced',\n",
       " 'processing',\n",
       " 'markdown',\n",
       " 'file',\n",
       " 'knit2html',\n",
       " 'function',\n",
       " 'knitr',\n",
       " 'package',\n",
       " '3',\n",
       " 'document',\n",
       " 'figure',\n",
       " 'included',\n",
       " 'placed',\n",
       " 'figure',\n",
       " 'directory',\n",
       " 'default',\n",
       " 'unless',\n",
       " 'overrode',\n",
       " 'default',\n",
       " 'add',\n",
       " 'commit',\n",
       " 'figure',\n",
       " 'directory',\n",
       " 'git',\n",
       " 'repository',\n",
       " '4',\n",
       " 'push',\n",
       " 'master',\n",
       " 'branch',\n",
       " 'github',\n",
       " '5',\n",
       " 'submit',\n",
       " 'url',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'assignment',\n",
       " 'course',\n",
       " 'web',\n",
       " 'site',\n",
       " 'addition',\n",
       " 'submitting',\n",
       " 'url',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'need',\n",
       " 'submit',\n",
       " '40',\n",
       " 'character',\n",
       " 'sha1',\n",
       " 'hash',\n",
       " 'string',\n",
       " 'number',\n",
       " '09',\n",
       " 'letter',\n",
       " 'af',\n",
       " 'identifies',\n",
       " 'repository',\n",
       " 'commit',\n",
       " 'contains',\n",
       " 'version',\n",
       " 'file',\n",
       " 'want',\n",
       " 'submit',\n",
       " 'github',\n",
       " 'following',\n",
       " '1',\n",
       " 'go',\n",
       " 'github',\n",
       " 'repository',\n",
       " 'web',\n",
       " 'page',\n",
       " 'assignment',\n",
       " 'click',\n",
       " 'commits',\n",
       " 'link',\n",
       " 'number',\n",
       " 'commits',\n",
       " 'repository',\n",
       " 'example',\n",
       " 'made',\n",
       " 'total',\n",
       " '10',\n",
       " 'commits',\n",
       " 'repository',\n",
       " 'link',\n",
       " 'say',\n",
       " '10',\n",
       " 'commits',\n",
       " '3',\n",
       " 'see',\n",
       " 'list',\n",
       " 'commits',\n",
       " 'made',\n",
       " 'repository',\n",
       " 'recent',\n",
       " 'commit',\n",
       " 'top',\n",
       " 'represents',\n",
       " 'version',\n",
       " 'file',\n",
       " 'want',\n",
       " 'submit',\n",
       " 'click',\n",
       " 'copy',\n",
       " 'clipboard',\n",
       " 'button',\n",
       " 'right',\n",
       " 'hand',\n",
       " 'side',\n",
       " 'appear',\n",
       " 'hover',\n",
       " 'sha1',\n",
       " 'hash',\n",
       " 'paste',\n",
       " 'sha1',\n",
       " 'hash',\n",
       " 'course',\n",
       " 'web',\n",
       " 'site',\n",
       " 'submit',\n",
       " 'assignment',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'use',\n",
       " 'recent',\n",
       " 'commit',\n",
       " 'go',\n",
       " 'find',\n",
       " 'commit',\n",
       " 'want',\n",
       " 'copy',\n",
       " 'sha1',\n",
       " 'hash',\n",
       " 'valid',\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a825fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rdpeng/ExData_Plotting1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nThis assignment uses data f...</td>\n",
       "      <td>introductionthi assign use data fromth uc irvi...</td>\n",
       "      <td>introductionthis assignment us data fromthe uc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdpeng/RepData_PeerAssessment1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nIt is now possible to colle...</td>\n",
       "      <td>introductionit possibl collect larg amount dat...</td>\n",
       "      <td>introductionit possible collect large amount d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataScienceSpecialization/courses</td>\n",
       "      <td>HTML</td>\n",
       "      <td>\\n### Data Science Specialization\\n\\nThese are...</td>\n",
       "      <td>data scienc specializationthes cours materi jo...</td>\n",
       "      <td>data science specializationthese course materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fighting41love/funNLP</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;center&gt;\\n    &lt;img style=\"border-radius: 0.312...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>magento/magento2</td>\n",
       "      <td>PHP</td>\n",
       "      <td>\\n&lt;p align=\"center\"&gt;\\n&lt;a href=\"https://www.cod...</td>\n",
       "      <td>magento open sourcewelcom magento open sourc p...</td>\n",
       "      <td>magento open sourcewelcome magento open source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rprokap/pset-9</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># pset-9\\n      CREDITS SEQUENCE              ...</td>\n",
       "      <td>pset9credit sequencenewspap headlin montagehea...</td>\n",
       "      <td>pset9credits sequencenewspaper headline montag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>konzy/mass_clone</td>\n",
       "      <td>Shell</td>\n",
       "      <td># mass_clone\\nThis is a shell script that will...</td>\n",
       "      <td>massclonethi shell script clone multipl reposi...</td>\n",
       "      <td>massclonethis shell script clone multiple repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>biter777/countries</td>\n",
       "      <td>Go</td>\n",
       "      <td># countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...</td>\n",
       "      <td>countriescountri iso 3166 iso31661 iso3166 dig...</td>\n",
       "      <td>countriescountries iso 3166 iso31661 iso3166 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>sayantann11/all-classification-templetes-for-ML</td>\n",
       "      <td>Python</td>\n",
       "      <td># all-classification-templetes-for-ML\\nClassif...</td>\n",
       "      <td>allclassificationtempletesformlclassif machin ...</td>\n",
       "      <td>allclassificationtempletesformlclassification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>denman2328/Help</td>\n",
       "      <td>None</td>\n",
       "      <td>------------------\\nSystem Information\\n------...</td>\n",
       "      <td>system informationtim report 8102013 083620 ma...</td>\n",
       "      <td>system informationtime report 8102013 083620 m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo    language  \\\n",
       "0                            rdpeng/ExData_Plotting1        None   \n",
       "1                     rdpeng/RepData_PeerAssessment1        None   \n",
       "2                  DataScienceSpecialization/courses        HTML   \n",
       "3                              fighting41love/funNLP      Python   \n",
       "4                                   magento/magento2         PHP   \n",
       "..                                               ...         ...   \n",
       "485                                   rprokap/pset-9  JavaScript   \n",
       "486                                 konzy/mass_clone       Shell   \n",
       "487                               biter777/countries          Go   \n",
       "488  sayantann11/all-classification-templetes-for-ML      Python   \n",
       "489                                  denman2328/Help        None   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "0    ## Introduction\\n\\nThis assignment uses data f...   \n",
       "1    ## Introduction\\n\\nIt is now possible to colle...   \n",
       "2    \\n### Data Science Specialization\\n\\nThese are...   \n",
       "3    <center>\\n    <img style=\"border-radius: 0.312...   \n",
       "4    \\n<p align=\"center\">\\n<a href=\"https://www.cod...   \n",
       "..                                                 ...   \n",
       "485  # pset-9\\n      CREDITS SEQUENCE              ...   \n",
       "486  # mass_clone\\nThis is a shell script that will...   \n",
       "487  # countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...   \n",
       "488  # all-classification-templetes-for-ML\\nClassif...   \n",
       "489  ------------------\\nSystem Information\\n------...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "0    introductionthi assign use data fromth uc irvi...   \n",
       "1    introductionit possibl collect larg amount dat...   \n",
       "2    data scienc specializationthes cours materi jo...   \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...   \n",
       "4    magento open sourcewelcom magento open sourc p...   \n",
       "..                                                 ...   \n",
       "485  pset9credit sequencenewspap headlin montagehea...   \n",
       "486  massclonethi shell script clone multipl reposi...   \n",
       "487  countriescountri iso 3166 iso31661 iso3166 dig...   \n",
       "488  allclassificationtempletesformlclassif machin ...   \n",
       "489  system informationtim report 8102013 083620 ma...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    introductionthis assignment us data fromthe uc...  \n",
       "1    introductionit possible collect large amount d...  \n",
       "2    data science specializationthese course materi...  \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...  \n",
       "4    magento open sourcewelcome magento open source...  \n",
       "..                                                 ...  \n",
       "485  pset9credits sequencenewspaper headline montag...  \n",
       "486  massclonethis shell script clone multiple repo...  \n",
       "487  countriescountries iso 3166 iso31661 iso3166 d...  \n",
       "488  allclassificationtempletesformlclassification ...  \n",
       "489  system informationtime report 8102013 083620 m...  \n",
       "\n",
       "[490 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_upper_outliers(s, k):\n",
    "    '''\n",
    "    Given a series and a cutoff value, k, returns the upper outliers for the\n",
    "    series.\n",
    "\n",
    "    The values returned will be either 0 (if the point is not an outlier), or a\n",
    "    number that indicates how far away from the upper bound the observation is.\n",
    "    '''\n",
    "    q1, q3 = s.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + k * iqr\n",
    "    return s.apply(lambda x: max([x - upper_bound, 0]))\n",
    "\n",
    "def add_upper_outlier_columns(df, k):\n",
    "    '''\n",
    "    Add a column with the suffix _outliers for all the numeric columns\n",
    "    in the given dataframe.\n",
    "    '''\n",
    "    # outlier_cols = {col + '_outliers': get_upper_outliers(df[col], k)\n",
    "    #                 for col in df.select_dtypes('number')}\n",
    "    # return df.assign(**outlier_cols)\n",
    "\n",
    "    for col in df.select_dtypes('number'):\n",
    "        df[col + '_outliers'] = get_upper_outliers(df[col], k)\n",
    "\n",
    "    return df\n",
    "\n",
    "add_upper_outlier_columns(df, k=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "910af5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_upper_outliers(s, k):\n",
    "    '''\n",
    "    Given a series and a cutoff value, k, returns the upper outliers for the\n",
    "    series.\n",
    "    The values returned will be either 0 (if the point is not an outlier), or a\n",
    "    number that indicates how far away from the upper bound the observation is.\n",
    "    '''\n",
    "    q1, q3 = s.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + (k * iqr)\n",
    "    return s.apply(lambda x: max([x - upper_bound, 0]))\n",
    "\n",
    "def add_upper_outlier_columns(df, k):\n",
    "    '''\n",
    "    Add a column with the suffix upper_outliers for all the numeric columns\n",
    "    in the given dataframe.\n",
    "    '''\n",
    "\n",
    "    for col in df.select_dtypes('number'):\n",
    "        df[col + '_upper_outliers'] = get_upper_outliers(df[col], k)\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df, k):\n",
    "    \"\"\"\n",
    "    removes rows of df that are outliers\n",
    "    \"\"\"\n",
    "    # df = add_upper_outlier_columns(df, k)\n",
    "    drop_list = list(df.select_dtypes('object').columns)\n",
    "    # IQR to detect and remove outliers\n",
    "    Q1 = df.drop(columns=drop_list).quantile(0.25)\n",
    "    Q3 = df.drop(columns=drop_list).quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[~((df.drop(columns=drop_list) < (Q1 - k * IQR)) | (df.drop(columns=drop_list) > (Q3 + k * IQR))).any(axis=1)]\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8ad1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e48c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols = [col for col in df if col.endswith('_outliers')]\n",
    "for col in outlier_cols:\n",
    "    print('~~~\\n' + col)\n",
    "    data = df[col][df[col] > 0]\n",
    "    print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bd6a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdfa805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "def detect_outliers_iqr(df):\n",
    "    data = sorted(df)\n",
    "    q1 = np.percentile(df, 25)\n",
    "    q3 = np.percentile(df, 75)\n",
    "    # print(q1, q3)\n",
    "    IQR = q3-q1\n",
    "    lwr_bound = q1-(1.5*IQR)\n",
    "    upr_bound = q3+(1.5*IQR)\n",
    "    # print(lwr_bound, upr_bound)\n",
    "    for i in df: \n",
    "        if (i<lwr_bound or i>upr_bound):\n",
    "            outliers.append(i)\n",
    "    return outliers# Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6cf1bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rdpeng/ExData_Plotting1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nThis assignment uses data f...</td>\n",
       "      <td>introductionthi assign use data fromth uc irvi...</td>\n",
       "      <td>introductionthis assignment us data fromthe uc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdpeng/RepData_PeerAssessment1</td>\n",
       "      <td>None</td>\n",
       "      <td>## Introduction\\n\\nIt is now possible to colle...</td>\n",
       "      <td>introductionit possibl collect larg amount dat...</td>\n",
       "      <td>introductionit possible collect large amount d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DataScienceSpecialization/courses</td>\n",
       "      <td>HTML</td>\n",
       "      <td>\\n### Data Science Specialization\\n\\nThese are...</td>\n",
       "      <td>data scienc specializationthes cours materi jo...</td>\n",
       "      <td>data science specializationthese course materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fighting41love/funNLP</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;center&gt;\\n    &lt;img style=\"border-radius: 0.312...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "      <td>nlpdatalogocitations487redsvgdatalogohomee4bab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>magento/magento2</td>\n",
       "      <td>PHP</td>\n",
       "      <td>\\n&lt;p align=\"center\"&gt;\\n&lt;a href=\"https://www.cod...</td>\n",
       "      <td>magento open sourcewelcom magento open sourc p...</td>\n",
       "      <td>magento open sourcewelcome magento open source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rprokap/pset-9</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># pset-9\\n      CREDITS SEQUENCE              ...</td>\n",
       "      <td>pset9credit sequencenewspap headlin montagehea...</td>\n",
       "      <td>pset9credits sequencenewspaper headline montag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>konzy/mass_clone</td>\n",
       "      <td>Shell</td>\n",
       "      <td># mass_clone\\nThis is a shell script that will...</td>\n",
       "      <td>massclonethi shell script clone multipl reposi...</td>\n",
       "      <td>massclonethis shell script clone multiple repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>biter777/countries</td>\n",
       "      <td>Go</td>\n",
       "      <td># countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...</td>\n",
       "      <td>countriescountri iso 3166 iso31661 iso3166 dig...</td>\n",
       "      <td>countriescountries iso 3166 iso31661 iso3166 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>sayantann11/all-classification-templetes-for-ML</td>\n",
       "      <td>Python</td>\n",
       "      <td># all-classification-templetes-for-ML\\nClassif...</td>\n",
       "      <td>allclassificationtempletesformlclassif machin ...</td>\n",
       "      <td>allclassificationtempletesformlclassification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>denman2328/Help</td>\n",
       "      <td>None</td>\n",
       "      <td>------------------\\nSystem Information\\n------...</td>\n",
       "      <td>system informationtim report 8102013 083620 ma...</td>\n",
       "      <td>system informationtime report 8102013 083620 m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo    language  \\\n",
       "0                            rdpeng/ExData_Plotting1        None   \n",
       "1                     rdpeng/RepData_PeerAssessment1        None   \n",
       "2                  DataScienceSpecialization/courses        HTML   \n",
       "3                              fighting41love/funNLP      Python   \n",
       "4                                   magento/magento2         PHP   \n",
       "..                                               ...         ...   \n",
       "485                                   rprokap/pset-9  JavaScript   \n",
       "486                                 konzy/mass_clone       Shell   \n",
       "487                               biter777/countries          Go   \n",
       "488  sayantann11/all-classification-templetes-for-ML      Python   \n",
       "489                                  denman2328/Help        None   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "0    ## Introduction\\n\\nThis assignment uses data f...   \n",
       "1    ## Introduction\\n\\nIt is now possible to colle...   \n",
       "2    \\n### Data Science Specialization\\n\\nThese are...   \n",
       "3    <center>\\n    <img style=\"border-radius: 0.312...   \n",
       "4    \\n<p align=\"center\">\\n<a href=\"https://www.cod...   \n",
       "..                                                 ...   \n",
       "485  # pset-9\\n      CREDITS SEQUENCE              ...   \n",
       "486  # mass_clone\\nThis is a shell script that will...   \n",
       "487  # countries\\r\\n\\r\\nCountries - ISO 3166 (ISO31...   \n",
       "488  # all-classification-templetes-for-ML\\nClassif...   \n",
       "489  ------------------\\nSystem Information\\n------...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "0    introductionthi assign use data fromth uc irvi...   \n",
       "1    introductionit possibl collect larg amount dat...   \n",
       "2    data scienc specializationthes cours materi jo...   \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...   \n",
       "4    magento open sourcewelcom magento open sourc p...   \n",
       "..                                                 ...   \n",
       "485  pset9credit sequencenewspap headlin montagehea...   \n",
       "486  massclonethi shell script clone multipl reposi...   \n",
       "487  countriescountri iso 3166 iso31661 iso3166 dig...   \n",
       "488  allclassificationtempletesformlclassif machin ...   \n",
       "489  system informationtim report 8102013 083620 ma...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    introductionthis assignment us data fromthe uc...  \n",
       "1    introductionit possible collect large amount d...  \n",
       "2    data science specializationthese course materi...  \n",
       "3    nlpdatalogocitations487redsvgdatalogohomee4bab...  \n",
       "4    magento open sourcewelcome magento open source...  \n",
       "..                                                 ...  \n",
       "485  pset9credits sequencenewspaper headline montag...  \n",
       "486  massclonethis shell script clone multiple repo...  \n",
       "487  countriescountries iso 3166 iso31661 iso3166 d...  \n",
       "488  allclassificationtempletesformlclassification ...  \n",
       "489  system informationtime report 8102013 083620 m...  \n",
       "\n",
       "[490 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_outliers(df,k=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_words = clean(' '.join(df[df.label == 'ham']['text']))\n",
    "spam_words = clean(' '.join(df[df.label == 'spam']['text']))\n",
    "all_words = clean(' '.join(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62ea58b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'word_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_dif \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_dif[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mword_count\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m      3\u001b[0m           df_no_outliers\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mword_count\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m df_dif[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpercent_change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  df_dif\u001b[38;5;241m.\u001b[39mmean_change \u001b[38;5;241m/\u001b[39m df_dif[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:904\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m--> 904\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'word_count'"
     ]
    }
   ],
   "source": [
    "df_dif = df.groupby('language').word_count.agg(['mean'])\n",
    "df_dif['mean_change'] = (df.groupby('language').word_count.agg('mean') -\n",
    "          df_no_outliers.groupby('language').word_count.agg('mean'))\n",
    "df_dif['percent_change'] =  df_dif.mean_change / df_dif['mean']\n",
    "df_dif = df_dif.reset_index()\n",
    "df_dif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81624b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
