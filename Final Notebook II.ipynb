{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed653a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import machine learning libaries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# import NLP tool\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "# import self-created functions\n",
    "import prepare\n",
    "import project_acquire\n",
    "import explore\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c0139",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use prepare module wrangle data function to acquire data\n",
    "data=pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we capture any duplicated repo/readme\n",
    "data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop those duplicated repo/readme\n",
    "data=data.drop_duplicates()\n",
    "data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe5f1e",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "- The readme acquired contains foreign language, we will going to drop those languages that is not in English, due to we acquired about 1000 rows, we met the requirement of at least 100 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e7131",
   "metadata": {},
   "source": [
    "#### Install the package needed to detect the language\n",
    "- \\# pip install langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5bfdb",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "- The most starred README data on github was collected on October 18, 2022 due to error code found, the previous dataset was deleted and re-collected on October 18th.\n",
    "- The data has 1000 rows\n",
    "- We found that the readme contains foreign language, therefore, we downloaded a langdetect package for further wrangle the dataset\n",
    "- we also spot some 'none' value in our language, we will do further wrangle with that data as well\n",
    "- Following this acquire, we are going to prepare for our exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89404f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data acquired\n",
    "# We are acquire the data that is cleaned up with tokenized, stemmed, and lemmatized\n",
    "# add those columns into the dataframe and create a final data frame\n",
    "df=prepare.wrangle_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5054be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will going to drop 'none' value in our language column\n",
    "df=df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will going to use the installed package \n",
    "# to filter out the readme contents that is in English only\n",
    "\n",
    "# we are going to import a new libary for this\n",
    "import langdetect as ld\n",
    "\n",
    "# we created a new function to detect the non-english language in read me\n",
    "# the function will return the result when it is not in english,, elso will not return the result\n",
    "def is_en(txt):\n",
    "    try:\n",
    "        return ld.detect(txt)!='en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# we applied the function we created \n",
    "nodf = df[df['readme_contents'].apply(is_en)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1450d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those that is not in english\n",
    "df=df.drop(index=(nodf.index))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffb932",
   "metadata": {},
   "source": [
    "- our dataframe should contains numerical data for better exploration, therefore, we are going to created some columns that able to represent the overall struture of the dataframe. we picked df.lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc96fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the explore module to create those numerical columns other neccessary info for exploration\n",
    "df=explore.feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa281ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a final local file for easy access\n",
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6eb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a079c",
   "metadata": {},
   "source": [
    "### Key takeaway so far\n",
    "- The numerical columns created for better exploration\n",
    "- The foreign language readme columns dropped to support our exploration\n",
    "- we ended up have 669 columns remained\n",
    "- The describe showed that there is significant jump in those counts, we believe we need to handle the outlier in our next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to trim the outlier and drop null values again\n",
    "def remove_outlier(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    new_df = ~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data after trim the outlier\n",
    "new_df=df[remove_outlier(df)]\n",
    "new_df=new_df.dropna()\n",
    "print('We drop ',round((1-len(new_df)/len(df))*100,2),'% rows due to outlier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a062e3",
   "metadata": {},
   "source": [
    "# Overall Wrangle Takeaway\n",
    "- The data aquired on October 18th, 2022 with 1000 rows\n",
    "- The data contains 'none' value in the language column, we dropped all 'none' values \n",
    "- The data contains foreign language in the readme contents column, we drop all those non-english values\n",
    "- We create some numerical columns for further exploration\n",
    "- we drop those outliers \n",
    "- We finalized with 586 rows, and ready for exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f4a32",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(25,20))\n",
    "continuous_data = new_df.select_dtypes(exclude=['object'])\n",
    "plt.suptitle(\"Distribution of Variable with Trend Line\")\n",
    "for i in range(0,8):\n",
    "    f.add_subplot(4,2, i+1)\n",
    "    sns.distplot(continuous_data.iloc[:,i], bins=3)\n",
    "plt.show()\n",
    "'''We are showing non-object histogram with a trendline, that the distribution of the data\n",
    "is normal for unique and repeat, \n",
    "but interestingly, the word count and non-single count is left skew'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c25074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the environment to answer those questions.\n",
    "# we find out that the top  5 languages are JavaScript, TypeScript, Python, Go and C++\n",
    "# We are going to drop other columns but keep those top 5 languages\n",
    "new_df.language.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to create the new dataframe\n",
    "a=['JavaScript', 'TypeScript', 'Python', 'Go', 'C++']\n",
    "exp_df=new_df[new_df.language.isin(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53dc946",
   "metadata": {},
   "source": [
    "## Q1: What are the most common words in READMEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39171ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the freq from created module \n",
    "freq_df=explore.freq_df(exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the top 10 most common word in read me\n",
    "freq_df.sort_values(by='all',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the percentage of JavaScript versus Python top 10 most common word by proportion\n",
    "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
    "(freq_df\n",
    " .assign(p_js=freq_df.JavaScript / freq_df['all'],\n",
    "         p_py=freq_df.Python / freq_df['all'],\n",
    "        p_tS=freq_df.TypeScript / freq_df['all'],\n",
    "        p_go=freq_df.Go / freq_df['all'],\n",
    "        p_c=freq_df['C++'] / freq_df['all'])\n",
    " .sort_values(by='all')\n",
    " [['p_js','p_tS','p_go','p_c', 'p_py']]\n",
    " .tail(10)\n",
    " .sort_values('p_js')\n",
    " .plot.barh(stacked=True))\n",
    "plt.title('Proportion of the 10 most common words by languages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bf6df",
   "metadata": {},
   "source": [
    "## Q1 Key Takeaway\n",
    "- The tope ten most used words are: use,install,using,run,file,build,code,version,support,project\n",
    "- The word build used significantly in c++ language while the javascript use all top 10 words consistently higher than others\n",
    "- The word 'use' and 'run' use less frequently in C++ language  \n",
    "- The word 'build' is less likely use in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10506c30",
   "metadata": {},
   "source": [
    "## Q2 Does the length of the README vary by programming language? If not whether the bigram different per language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aadbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2=exp_df.copy()\n",
    "q2.groupby('language')['word_count'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24766f",
   "metadata": {},
   "source": [
    "#### Q2 key takeaway so far\n",
    "- No, the length of the README is not vary by the programming language.\n",
    "- We will explore bigram per language next to further explore whether the bigram is different by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram per language, we will extract already build function in explore module\n",
    "q2_2=explore.bigram_clean(exp_df)\n",
    "q2_2.sort_values(by='all_bigram',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205544b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
    "(q2_2\n",
    " .assign(p_js=q2_2.JavaScript / q2_2['all_bigram'],\n",
    "         p_py=q2_2.Python / q2_2['all_bigram'],\n",
    "        p_tS=q2_2.TypeScript / q2_2['all_bigram'],\n",
    "        p_go=q2_2.Go / q2_2['all_bigram'],\n",
    "        p_c=q2_2['C++'] / q2_2['all_bigram'])\n",
    " .sort_values(by='all_bigram')\n",
    " [['p_js','p_py','p_tS','p_go', 'p_c']]\n",
    " .tail(10)\n",
    " .sort_values('p_js')\n",
    " .plot.barh(stacked=True))\n",
    "plt.title('Proportion of the 10 most common bigram words by languages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab90e5",
   "metadata": {},
   "source": [
    "## Q2: Key Takeaway:\n",
    "- The Python and TypeScript has unique word that belong to them in bigram\n",
    "- The language itself doesn't varied the progrma language readme length\n",
    "- The Bigram has significant different in different language\n",
    "- Interestingly, the python bigram ''et, al'' has not seem before, potentially suspected the code broke somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7d121",
   "metadata": {},
   "source": [
    "## Q3: Do different programming languages use a different number of unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd41a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e4893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce912a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.vis_cloud(exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba3256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(exp_df.lemmatized)\n",
    "y = exp_df.language\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=13)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .25, random_state=13)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=12, random_state=123)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy Score: {tree.score(X_val, y_val) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe74ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(exp_df.lemmatized)\n",
    "y = exp_df.language\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=13)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .25, random_state=13)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=17, random_state=13)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy Score: {tree.score(X_val, y_val) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "X = cv.fit_transform(exp_df.lemmatized)\n",
    "y = exp_df.language\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=13)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .25, random_state=13)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=16, random_state=13)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy Score: {tree.score(X_val, y_val) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60805763",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(3, 3))\n",
    "X = cv.fit_transform(exp_df.lemmatized)\n",
    "y = exp_df.language\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=13)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .25, random_state=13)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=15, random_state=13)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy Score: {tree.score(X_val, y_val) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4abd16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
